{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "source": [
    "# <i>My First</i> <b>Machine Learning</b> <i>Program</i>\n",
    "###### <i>...that works (so far....) :-)</i>\n",
    "\n",
    "by Soegha (soegha@gmail.com)\n",
    "\n",
    "This python program is an adaptation from a SUPERB article of <br>\n",
    "\"Implementation of Artificial Neural Network in Python\" by Aqsa Zafar <br>(https://www.mltut.com/implementation-of-artificial-neural-network-in-python/)\n",
    "\n",
    "The original article is written at (<i>my guess...</i>) python2 and I update some portion of it to python3 and its ascociated library.<br>\n",
    "This python version was selected because the newest python version at the time (python 3.13) did not support tensorflow and keras module, yet.\n",
    "\n",
    "\n",
    "### This program was tested at machine with below environment setting:\n",
    "<ul>\n",
    "<li>python 3.10.11</li>\n",
    "<li>pandas 2.2.2</li>\n",
    "<li>numpy 1.26.4</li>\n",
    "<li>matplotlib 3.9.2</li>\n",
    "<li>scikit-learn 1.5.1</li>\n",
    "<li>tensorflow 2.17.0</li>\n",
    "<li>keras 3.5.0</li>\n",
    "</ul>\n",
    "<br>\n",
    "\n",
    "<i><b>Warning:</b><br> \n",
    "<ul>\n",
    "<li>running this program on different version of python and/or library will possibly create different result / warning / error</li>\n",
    "<li>Use this program at your own risk</li>\n",
    "</ul></i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the libraries required\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the dataset from csv file\n",
    "dataset = pd.read_csv('Churn_Modelling.csv')\n",
    "#print(dataset[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the dataset into X and y\n",
    "#select only column 4 (index=3) up to column 14 (index=13) --> first column index=0\n",
    "X = pd.DataFrame(dataset.iloc[:, 3:13].values)\n",
    "y = dataset.iloc[:, 13].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the library required\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "\n",
    "#label Gender variable (male, female) into (1,0)\n",
    "labelencoder_X_2 = LabelEncoder()\n",
    "X.loc[:, 2] = labelencoder_X_2.fit_transform(X.iloc[:, 2])\n",
    "#print(X[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the library required\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "#convert Geography variable into One Hot Encoding (like 1,0,0 etc) and put it in the first 3 column\n",
    "ct = ColumnTransformer([(\"Country\", OneHotEncoder(), [1])], remainder = 'passthrough')\n",
    "X = ct.fit_transform(X)\n",
    "#print(X[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import again.....\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#split X and y data into training se and testing set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.01460667 -0.5698444   1.74309049  0.16958176 -1.09168714 -0.46460796\n",
      "   0.00666099 -1.21571749  0.8095029   0.64259497 -1.03227043  1.10643166]\n",
      " [-1.01460667  1.75486502 -0.57369368 -2.30455945  0.91601335  0.30102557\n",
      "  -1.37744033 -0.00631193 -0.92159124  0.64259497  0.9687384  -0.74866447]\n",
      " [ 0.98560362 -0.5698444  -0.57369368 -1.19119591 -1.09168714 -0.94312892\n",
      "  -1.031415    0.57993469 -0.92159124  0.64259497 -1.03227043  1.48533467]]\n"
     ]
    }
   ],
   "source": [
    "#import again....\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#perform feature scaling, so all values are in the same range.\n",
    "#same scaling will reduce calculation time\n",
    "#always do this, even when you have value of o (zero)\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "print(X_train[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This is the Neural Network that we want to replicate<br>\n",
    "![Neural Network](Neural_Network.png) \n",
    "<br><br>\n",
    "#### And this is the artificial model that we will develop<br>\n",
    "![Artificial Neural Network](Artificial_Neural_Network.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#built Artificial Neural Network (ANN)\n",
    "#first step: import the libraries.....\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.7941 - loss: 0.5407\n",
      "Epoch 2/10\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8068 - loss: 0.4572\n",
      "Epoch 3/10\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7927 - loss: 0.4468\n",
      "Epoch 4/10\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7989 - loss: 0.4250\n",
      "Epoch 5/10\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8209 - loss: 0.4210\n",
      "Epoch 6/10\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8201 - loss: 0.4193\n",
      "Epoch 7/10\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8209 - loss: 0.4251\n",
      "Epoch 8/10\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8392 - loss: 0.3907\n",
      "Epoch 9/10\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8272 - loss: 0.4093\n",
      "Epoch 10/10\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8265 - loss: 0.4221\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x2617565fdc0>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#initialize ANN model\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Input(shape=(12,)))  # Specify the input shape\n",
    "model.add(Dense(6, activation='relu'))  # Add 1st hidden layer with 6 units and ReLU activation\n",
    "model.add(Dense(6, activation='relu'))  # Add 2nd hidden layer with 6 units and ReLU activation\n",
    "model.add(Dense(1, activation='sigmoid'))  # Add the output layer with 1 unit and sigmoid activation\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "#train the model\n",
    "model.fit(X_train, y_train, batch_size = 10, epochs= 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n"
     ]
    }
   ],
   "source": [
    "#predict the test result test\n",
    "y_pred = model.predict(X_test)\n",
    "#print(y_pred[:15])\n",
    "\n",
    "#plot it if you want\n",
    "#plt.scatter(y_test, y_pred)\n",
    "#plt.xlabel('True Value')\n",
    "#plt.ylabel(\"Predicted\")\n",
    "#plt.axis('equal')\n",
    "#plt.axis('square')\n",
    "#plt.plot(y_test - y_pred,marker='o',linestyle='')\n",
    "\n",
    "# mapping predicted value to boolean\n",
    "y_pred = (y_pred > 0.5)\n",
    "#print(y_pred[:15])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1564   31]\n",
      " [ 289  116]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.84"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import the library\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "#create confusion matrix to calculate the accuracy of predicted value\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "accuracy_score(y_test,y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
